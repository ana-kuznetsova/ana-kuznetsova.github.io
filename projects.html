<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Projects - Anastasia Kuznetsova</title>
    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
</head>

<body>
    <header>
        <div class="container">
            <div class="header-content">
                <img src="profile.jpg" alt="Anastasia Kuznetsova" class="profile-pic">
                <div class="header-text">
                    <h1>Anastasia Kuznetsova</h1>
                    <p>PhD Candidate in Computer Science and Computational Linguistics</p>
                    <p>Indiana University Bloomington</p>
                </div>
            </div>
        </div>
    </header>
    <nav>
        <div class="container">
            <ul>
                <li><a href="index.html#home">Home</a></li>
                <li><a href="index.html#research">Research</a></li>
                <li><a href="index.html#publications">Publications</a></li>
                <li><a href="index.html#education">Education</a></li>
                <li><a href="index.html#teaching">Teaching</a></li>
                <li><a href="index.html#awards">Awards</a></li>
                <li><a href="index.html#services">Services</a></li>
                <li><a href="projects.html">Projects</a></li>
                <li><a href="index.html#cv">CV</a></li>
                <li><a href="index.html#contact">Contact</a></li>
            </ul>
        </div>
    </nav>
    <section id="projects">
        <div class="container">
            <h2>Projects</h2>
            <div class="project-item">
                <div class="tags">
                    <span class="tag">ASR</span>
                    <span class="tag">Discrete tokens</span>
                    <span class="tag">Neural codecs</span>
                </div>
                <h3>Discrete encoder representations for ASR</h3>
                <p>Discrete audio and semantic tokens inspired by large language models gained popularity
                    not only in natural language processing but also in speech and audio applications.
                    The potential of neural codecs and semantic SSL representations has been vastly explored
                    for reducing the training complexity of a variety of the downstream tasks.
                    However, for the transmission and
                    communication scenarios, when the ASR system is deployed on the edge devices, the bitrate
                    of the speech tokens is of the utmost importance. In this project, we explore the lower bound
                    of the bitrate of the discrete representations for ASR systems without loss of the recognition
                    accuracy. To save the space on device and reduce the transmission latency, we propose quantization
                    method for the ASR encoder.
                </p>
            </div>
            <div class="project-item">
                <div class="tags">
                    <span class="tag">Personalization</span>
                    <span class="tag">Speech enhancement</span>
                    <span class="tag">Data augmentation</span>
                    <span class="tag">Speech synthesis</span>
                    <span class="tag">ICASSP 2023</span>
                </div>
                <h3>The Potential of Neural Speech Synthesis-Based Data Augmentation for Personalized Speech Enhancement
                </h3>
                <div class="project-content">
                    <div class="project-text">
                        <p>With the advances in deep learning, speech enhancement systems
                            benefited from large neural network architectures and achieved stateof-the-art quality.
                            However, speaker-agnostic methods are not always desirable, both in terms of quality and
                            their complexity, when
                            they are to be used in a resource-constrained environment. One
                            promising way is personalized speech enhancement (PSE), which is
                            a smaller and easier speech enhancement problem for small models
                            to solve, because it focuses on a particular test-time user. To achieve
                            the personalization goal, while dealing with the typical lack of personal data, we
                            investigate the effect of data augmentation based on
                            neural speech synthesis (NSS). In the proposed method, we show
                            that the quality of the NSS system’s synthetic data matters, and if
                            they are good enough the augmented dataset can be used to improve
                            the PSE system that outperforms the speaker-agnostic baseline. The
                            proposed PSE systems show significant complexity reduction while
                            preserving the enhancement quality.
                        </p>
                        <a href="https://arxiv.org/pdf/2211.07493" target="_blank">[Paper]</a>
                        <a href="https://iu.mediaspace.kaltura.com/media/t/1_w9qjy9wi" target="_blank">[Demo]</a>
                    </div>
                    <img src="img/pse_img.jpg" alt="pse_diagram" class="project-image">
                </div>
            </div>
            <div class="project-item">
                <div class="tags">
                    <span class="tag">Curriculum Learning</span>
                    <span class="tag">ASR</span>
                    <span class="tag">Reinforcement Learning</span>
                </div>
                <h3>Curriculum optimization for low-resource speech recognition</h3>
                <div class="project-content">
                    <div class="project-text">
                        <p>End-to-end speech recognition models show astonishing results in transcribing audio signals
                            into written text.
                            However, conventional data feeding pipelines may be suboptimal for low-resource speech
                            recognition, which still remains a challenging task. We propose an automated curriculum
                            learning approach to optimize the sequence of training
                            examples based on both the progress of the model while training and prior knowledge about
                            the difficulty of the training
                            examples. We introduce a new difficulty measure called compression ratio that can be used as
                            a scoring function for raw
                            audio in various noise conditions. The proposed method improves speech recognition Word
                            Error Rate performance by
                            up to 33% relative over the baseline system</p>
                        <a href="https://ieeexplore.ieee.org/document/9746674" target="_blank">[Paper]</a>
                        <a href="files/ICASSP2022_Poster.pdf" target="_blank">[Poster]</a>
                    </div>
                    <figure class="project-image-container">
                        <img src="img/snr_cr.png" alt="snr_cr_dependence" class="project-image">
                        <figcaption>Compression ratio vs. SNR.</figcaption>
                    </figure>
                </div>
            </div>
            <!-- Add more project items as needed -->
        </div>
    </section>
    <section id="linguistics-projects">
        <div class="container">
            <h2>Linguistics Projects</h2>
            <div class="project-item">
                <div class="tags">
                    <span class="tag">Morphological Analysis</span>
                    <span class="tag">Finite-State Transducers</span>
                </div>
                <h3>Finite-State Morphological Analyser for Paraguayan Guaraní</h3>
                <div class="project-content">
                    <div class="project-text">
                        <p>This project involves developing a finite-state morphological analyser for Paraguayan Guaraní, an indigenous language spoken in Paraguay. The analyser uses finite-state transducers to model the morphological processes of the language, enabling accurate analysis and generation of word forms.</p>
                        <a href="https://example.com/project-link-4" target="_blank">[Paper]</a>
                        <a href="https://example.com/project-demo-4" target="_blank">[Demo]</a>
                    </div>
                    <img src="img/guarani_morphology.jpg" alt="Guaraní Morphology" class="project-image">
                </div>
            </div>
            <div class="project-item">
                <div class="tags">
                    <span class="tag">Morphological Analysis</span>
                    <span class="tag">Finite-State Transducers</span>
                </div>
                <h3>Finite-State Morphological Analyser for Evenki</h3>
                <div class="project-content">
                    <div class="project-text">
                        <p>This project involves developing a finite-state morphological analyser for Evenki, a Tungusic language spoken in Siberia. The analyser uses finite-state transducers to model the morphological processes of the language, enabling accurate analysis and generation of word forms.</p>
                        <a href="https://example.com/project-link-5" target="_blank">[Paper]</a>
                        <a href="https://example.com/project-demo-5" target="_blank">[Demo]</a>
                    </div>
                    <img src="img/evenki_morphology.jpg" alt="Evenki Morphology" class="project-image">
                </div>
            </div>
        </div>
    </section>
    <footer>
        <div class="container">
            <p>&copy; 2024 Anastasia Kuznetsova. All rights reserved.</p>
        </div>
    </footer>